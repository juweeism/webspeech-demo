{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI, Request, status\n",
    "from fastapi.responses import Response\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import uvicorn\n",
    "from pydantic import BaseModel\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import openai\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from openai import OpenAI\n",
    "import ast\n",
    "import json\n",
    "from fastapi.middleware.cors import CORSMiddleware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not len(OPENAI_API_KEY):\n",
    "    print(\"Set OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Speech(BaseModel):\n",
    "    excerpt:str\n",
    "    previous_suggestion:str\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "origins = [\n",
    "    \"http://localhost:4321\",\n",
    "]\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=origins,\n",
    "    allow_credentials = True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_speech(excerpt, previous_suggestion):\n",
    "    prompt = [{\"role\":\"system\",\"content\":'''Your job is to continue my speech in 1 sentence. I will be \n",
    "               giving you a live transcript of my speech. Your output should be a json with only one key,\n",
    "               next_sentence. I choose whether to follow your suggestion. If I seem to be following your \n",
    "               suggestion and I am not yet done reading your suggestion aloud, just output your previous suggestion.\n",
    "               Otherwise, just output a new sentence to continue my speech.'''},\n",
    "               {\"role\":\"user\",\"content\":f\"Previous suggestion: {previous_suggestion}\"},\n",
    "               {\"role\":\"user\",\"content\":f\"Live speech transcript: {excerpt}\"}\n",
    "\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.post(\"/generate_speech\",status_code=status.HTTP_202_ACCEPTED)\n",
    "def continue_speech(speech:Speech):\n",
    "    try:\n",
    "        print(speech.excerpt)\n",
    "        client = OpenAI()\n",
    "        response = client.chat.completions.create(\n",
    "            model = \"gpt-3.5-turbo-0125\",\n",
    "            response_format={\"type\":\"json_object\"},\n",
    "            temperature=0.7,\n",
    "            messages=generate_speech(excerpt=speech.excerpt,previous_suggestion=speech.previous_suggestion)\n",
    "        )\n",
    "        print(response)\n",
    "        return response\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"ERROR!\")\n",
    "        return {\"Error\":e}\n",
    "\n",
    "uvicorn.run(app,host=\"192.168.0.23\",port=8080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm so today you will be talking about the circadian rhythm\n",
      "ERROR!\n",
      "INFO:     192.168.0.23:58912 - \"POST /generate_speech HTTP/1.1\" 500 Internal Server Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 230, in jsonable_encoder\n",
      "    data = dict(obj)\n",
      "TypeError: '_ssl._SSLSocket' object is not iterable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 235, in jsonable_encoder\n",
      "    data = vars(obj)\n",
      "TypeError: vars() argument must have __dict__ attribute\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 408, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 84, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\applications.py\", line 292, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\applications.py\", line 122, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 184, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 162, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\middleware\\cors.py\", line 91, in __call__\n",
      "    await self.simple_response(scope, receive, send, request_headers=headers)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\middleware\\cors.py\", line 146, in simple_response\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 79, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 68, in __call__\n",
      "    await self.app(scope, receive, sender)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\middleware\\asyncexitstack.py\", line 20, in __call__\n",
      "    raise e\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\middleware\\asyncexitstack.py\", line 17, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 718, in __call__\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 276, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 66, in app\n",
      "    response = await func(request)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\routing.py\", line 291, in app\n",
      "    content = await serialize_response(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\routing.py\", line 179, in serialize_response\n",
      "    return jsonable_encoder(response_content)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 195, in jsonable_encoder\n",
      "    encoded_value = jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 239, in jsonable_encoder\n",
      "    return jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 195, in jsonable_encoder\n",
      "    encoded_value = jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 239, in jsonable_encoder\n",
      "    return jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 195, in jsonable_encoder\n",
      "    encoded_value = jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 195, in jsonable_encoder\n",
      "    encoded_value = jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 239, in jsonable_encoder\n",
      "    return jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 195, in jsonable_encoder\n",
      "    encoded_value = jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 239, in jsonable_encoder\n",
      "    return jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 195, in jsonable_encoder\n",
      "    encoded_value = jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 238, in jsonable_encoder\n",
      "    raise ValueError(errors) from e\n",
      "ValueError: [TypeError(\"'_ssl._SSLSocket' object is not iterable\"), TypeError('vars() argument must have __dict__ attribute')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm so today you will be talking about the circadian rhythm\n",
      "ERROR!\n",
      "INFO:     192.168.0.23:58919 - \"POST /generate_speech HTTP/1.1\" 500 Internal Server Error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 230, in jsonable_encoder\n",
      "    data = dict(obj)\n",
      "TypeError: '_ssl._SSLSocket' object is not iterable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 235, in jsonable_encoder\n",
      "    data = vars(obj)\n",
      "TypeError: vars() argument must have __dict__ attribute\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 408, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 84, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\applications.py\", line 292, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\applications.py\", line 122, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 184, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 162, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\middleware\\cors.py\", line 91, in __call__\n",
      "    await self.simple_response(scope, receive, send, request_headers=headers)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\middleware\\cors.py\", line 146, in simple_response\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 79, in __call__\n",
      "    raise exc\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 68, in __call__\n",
      "    await self.app(scope, receive, sender)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\middleware\\asyncexitstack.py\", line 20, in __call__\n",
      "    raise e\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\middleware\\asyncexitstack.py\", line 17, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 718, in __call__\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 276, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\starlette\\routing.py\", line 66, in app\n",
      "    response = await func(request)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\routing.py\", line 291, in app\n",
      "    content = await serialize_response(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\routing.py\", line 179, in serialize_response\n",
      "    return jsonable_encoder(response_content)\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 195, in jsonable_encoder\n",
      "    encoded_value = jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 239, in jsonable_encoder\n",
      "    return jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 195, in jsonable_encoder\n",
      "    encoded_value = jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 239, in jsonable_encoder\n",
      "    return jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 195, in jsonable_encoder\n",
      "    encoded_value = jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 195, in jsonable_encoder\n",
      "    encoded_value = jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 239, in jsonable_encoder\n",
      "    return jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 195, in jsonable_encoder\n",
      "    encoded_value = jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 239, in jsonable_encoder\n",
      "    return jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 195, in jsonable_encoder\n",
      "    encoded_value = jsonable_encoder(\n",
      "  File \"c:\\Users\\Padfoot\\anaconda3\\lib\\site-packages\\fastapi\\encoders.py\", line 238, in jsonable_encoder\n",
      "    raise ValueError(errors) from e\n",
      "ValueError: [TypeError(\"'_ssl._SSLSocket' object is not iterable\"), TypeError('vars() argument must have __dict__ attribute')]\n",
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [22944]\n"
     ]
    }
   ],
   "source": [
    "@app.post(\"/generaye_speech\",status_code=status.HTTP_202_ACCEPTED)\n",
    "def continue_speech(speech=Speech):\n",
    "    try:\n",
    "        print(speech.excerpt)\n",
    "        client = OpenAI()\n",
    "        print(generate_speech(excerpt=speech.excerpt,previous_suggestion=speech.previous_suggestion))\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            response_format={\"type\":\"json_object\"},\n",
    "            temperature=0.7,\n",
    "            messages=generate_speech(excerpt=speech.excerpt,previous_suggestion=speech.previous_suggestion)\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error\")\n",
    "        return {\"Error\":e}\n",
    "\n",
    "uvicorn.run(app,host=\"192.168.0.23\",port=8080)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
